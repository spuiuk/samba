TODOs for multi-channel
=======================

- create replay:
  --------------
  Questions: (==> torture tests)
  - are fields / create contexts of the replayed request
    checked against the original request?
    ==> partly covered by tests
  - do differences lead to errors?
    ==> partly covered by tests
  - what is used to compose the reply to the replayed create?
    original request or replayed requetst...

  e.g.:
  - original request had a batch lease, but replayed has a read lease
  - original request has different access mask than replayed one
  - original request has different share mode than replated one


- channel sequence number
  -----------------------

  - overflow handling ...


- preview-diff doc ms-smb2, june22:
  p 297, create validation:

  "If CreateOptions includes FILE_NO_INTERMEDIATE_BUFFERING and
  DesiredAccess includes FILE_APPEND_DATA, the server MUST set
  FILE_APPEND_DATA to zero in the DesiredAccess field in the
  request."

- test / find / fix: dgram messaging send hangs for data (iov) of 30K

- in session bind: verify same clientGUID and smb dialect as existing sessions

  !! According to latest comments and preview docs by Microsoft,
  !! is the ClientGUID reliable enough to be used by us for the
  !! purpose of pro-actively moving connections to an smbd that
  !! is already serving connections from the same GUID?
  !!
  !! The new diff doc (June22) is at least inconsistent in that
  !! it removes the ClientGUID from the lease-identifyer....
  !!
  !! ==> Currently in clarification.

- index for CreateGUID->smbXsrv_open entry to support create replay


- oplock breaks (replay):
  ----------------------

  when we send oplock/lease break,
  then we need to make sure that the client receives it.
  problematic case is when a channel failure occurs
  while we send this out. The client may not have
  received it (in which case we need to retry on a diffrent
  channel), or it may have sent out the ACK on a different
  channel, in which case we are good.

  => possibility: watch TCP state to verify
  => have (hack) patch in the tree
     (using IPPROTO_TCP TCP_INFO ...)
     TODO: do better (?)
     how portable is this? ((Free)BSD, *solaris)
  => possibly implement support for IPPROTO_TCP TCP_INFO
     in socket wrapper to test it

  possibly at first without IPPROTO ... :

  - send oplock/lease break
  - start main timer for OPLOCK_BREAK_TIMEOUT(30) seconds
  - Save FileId for oplock breaks, LeaseKey for lease breaks in pending_breaks
    list for client
  - If connection has multiple channels, start a 5 second connection timer.
    - If connection timer expires, lookup next available channel and resend
      request over new channel.
    - if no more channels available, cancel timer and await main timer timeout
    - else resend break request and reset connection timer.
  - if oplock/lease break reply comes in, compare FileId for oplock breaks,
    LeaseKey for lease breaks in pending_breaks list for client. If exists,
    wake up main request, remove from pending_list, disable timer and clean up
    memory.
  - if timer expires: return timeout. New create request allowed to proceed.

- interface characteristics:
  --------------------------

  how to do it?
  - ethtool-like for linux
    ==> DONE
  - bsd/solaris
  - smb.conf option (interfaces = IP:bw)
    ==> DONE

- clustering/ctdb:
  ---------------

  - MC addresses should not be ctdb public addresses
  - for clustering = yes, each IF should have a static IP address in addition
    to the public ones, only the static ones would get listed in the
    query interfaces response.

  - QUESTIONS:

    - what happens if an initial connection is made through a
      ctdb public address, and then a network interface info
      ioctl is received? --> only reply with the single
      public address for this? and only give more addresses
      in the ioctl reply if the initial request was done
      through a static address?
      ==> doesn't this invalidate the ctdb clustering concept to an extend?

    - What happens if a session bind is done on a connection
      that was NOT provided as part of a query network interface info
      response? If this is allowed, we have a fundamental problem
      because clients can try to bind to any address that belongs
      to the node, or even to the cluster.
      ==> danger of node-spanning MC-sessions



- session bind vs. previous_session_id:
  doc (3.3.5.5 and 3.3.5.5.3) seems to imply
  that session reconnect at session bind is OK

  TODO: verify


tests:

- multi-channel support in smbclient?

- torture-test:

  - smbtorture bench
  - # channels -> open channels
  - file: size = (#channels) * chunk-size (8mb) [ or chunk-size ]
  - open
  - read on each channel in a loop
  - async smbXcli_read .... for each channel (in event-loop)

  - alterantively:
  - open conn
  - open file
  - make #channel forks
  - create channel in child
  - (only possibly problematic if using encryption,
     could give each connection/client nonce offset)


-----------------------------------------------------------

-2 clients (with different client GUIDs)
 client1 -> channel A
 client2 -> channel A,B
 2A open -> file1
 2B open -> file2
 1A opens file1 batchoplock
 1A opens file2 batchoplock

-----------------------------------------------------------

Windows server will start sending tcp 10 keepalive packets after 10 seconds for
shares with continously availability bit set.

https://www.snia.org/sites/default/orig/SDC2012/presentations/Revisions/DavidKruse_MGeorge_Continuously_Available%20SMB_v3-Revision.pdf

 from the tcp manpage:

        tcp_keepalive_intvl (integer; default: 75; since Linux 2.4)
              The number of seconds between TCP keep-alive probes.

       tcp_keepalive_probes (integer; default: 9; since Linux 2.2)
              The maximum number of TCP keep-alive probes to send before giving up and killing the connection if no response is obtained from the other end.

       tcp_keepalive_time (integer; default: 7200; since Linux 2.2)
              The number of seconds a connection needs to be idle before TCP begins sending out keep-alive probes.  Keep-alives are sent only when  the  SO_KEEPALIVE  socket  option  is
              enabled.   The  default value is 7200 seconds (2 hours).  An idle connection is terminated after approximately an additional 11 minutes (9 probes an interval of 75 seconds
              apart) when keep-alive is enabled.

              Note that underlying connection tracking mechanisms and application timeouts may be much shorter.

 Windows 2016 uses:
	tcp_keepalive_intvl 1
	tcp_keepalive_probes 10
	tcp_keepalive_time 10


	in smb.conf:

		socket options = SO_KEEPALIVE TCP_KEEPCNT=10 TCP_KEEPIDLE=10 TCP_KEEPINTVL=1


default settings:
[root@mthelena samba.git]# cat /proc/sys/net/ipv4/tcp_retries1 
3
[root@mthelena samba.git]# cat /proc/sys/net/ipv4/tcp_retries2
15


retries	| 1 2 3 4  5  6
seconds	| 1 3 7 15 31 63
          1 2 4 8  16 32

-----------------------------------------------------------

[MS-SMB2]
Footnote 157 explains semantics to choose MC interface from a list of interfaces

<157> Section 3.2.5.5: Windows-based SMB2 clients will choose the interfaces
using the following
criteria:
1. Skip the interfaces in NETWORK_INTERFACE_INFO Response where IfIndex is 0.
2. For each interface returned in NETWORK_INTERFACE_INFO Response, if the
interface has both
link-local and non-link-local IP addresses, skip the link-local IP address.
3. If there is one or more multiple link-local addresses (suppose there are Y
		such interfaces), select
local interfaces which only have link-local addresses (suppose there are X such
		local interfaces).
4. Build a destination address list, include all server non-link-local addresses
and X*Y server link-
local addresses.
5. For each RDMA capable address pair, duplicate the address pair, one for RDMA
and one for Direct
TCP.
6. Sort address pairs by which address pair is best suited for connection
between client and server.
7. For each address pair, compute
 Link speed of the pair = min( link speed of local interface, link speed of
		remote interface)
 RSS capable = RSS capable of local interface and RSS capable of remote
interface
8. If there are RDMA capable address pairs, select them.
 Otherwise if there are RSS capable address pairs, select them.
 Otherwise select remaining address pairs.
9. Select the pairs with the highest link speed from the selected address pairs.
10. Select local/remote address pairs so that all eligible local/remote
interfaces are used and the
connections are distributed among local and remote interfaces.
11. The client attempts to establish an alternate channel on each selected
interface and address pair.
The client will create only a single connection per address pair when the server
interface is neither
RSS- nor RDMA-capable.

-----------------------------------------------------------

https://blogs.technet.microsoft.com/josebda/2018/02/21/path-to-the-server-an-ode-to-smb-multichannel/

Path to the Server (An Ode to SMB Multichannel)
	★★★★★
	★★★★
	★★★
	★★
	★
	avatar of jose-barreto-2JoseBarretoFebruary 21, 20180	

	    1
	        0

		Read while listening to
		https://www.youtube.com/watch?v=iXQUu5Dti4g 

		 

		Path to the Server
		On Ode to SMB Multichannel
		by Jose Barreto

		 

		There’s a client somewhere looking for file shares
		And it’s finding a path to the server
		When it gets there it knows it can read, write and close
		With a word it can get what it came for

		Ooh, ooh, and it’s finding a path to the server

		DNS is involved, but it needs to resolve
		‘Cause you know sometimes names have two IPs.
		In a dim server room, there is an admin who says:
		Sometimes not all our addresses are given.

		Ooh, it makes me wonder,
		Ooh, it makes me wonder.

		There’s a feeling, a twitch, when I look at the switch,
		And my clients are crying for bandwidth.
		In my thoughts I have seen
		packets route out and in,
		And the voices of those who stand waiting.

		Ooh, it makes me wonder,
		Ooh, really makes me wonder.

		And it’s whispered to me if on SMB 3
		Then the prot’col will lead us to reason.
		And a new day will dawn for those file servers
		And the clients will echo with laughter.

		If you see a few more connections,
		Don’t be alarmed now,
		It’s just some multichannel action.
		Yes, there are two paths you can go by but if one’s gone
		There’s still time to change the queue you’re on.

		And it makes me wonder.
		Ooooooh…

		You server is humming, speed is twofold,
		In case you don’t know:
		You are now balancing your net load.

		Dear client, you’re now multipathing,
		And just one more thing:
		You will recover when your network fails.

		Now we can read and write much more,
		Our bandwidth higher than before,
		There goes the server we all know.
		Who perform betters and wants to show
		How everything’s still just a share
		And if you look it really hard
		You’ll see pieces that we shard.
		When there are multiple of all you got,
		You’ll see a fail but you won’t stop.

		And it’s finding the path to… the server…

